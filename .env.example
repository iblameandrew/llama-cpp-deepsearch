# LLM Provider: ollama, lmstudio, llama_cpp, openrouter
LLM_PROVIDER=ollama

# Model name (depends on provider)
# Ollama: llama3.2, deepseek-r1:7b, qwen2.5:14b, etc.
# LMStudio: qwen_qwq-32b, llama-3.1-8b-instruct, etc.
# llama_cpp: model filename (e.g., model.gguf)
# OpenRouter: stepfun/step-3.5-flash:free, etc.
LOCAL_LLM=llama3.2

# Provider URLs
OLLAMA_BASE_URL=http://localhost:11434
LMSTUDIO_BASE_URL=http://localhost:1234/v1
LLAMA_CPP_BASE_URL=http://127.0.0.1:8080/v1

# OpenRouter (optional - for cloud models)
OPENROUTER_API_KEY=
OPENROUTER_MODEL=stepfun/step-3.5-flash:free

# Search API: tavily, perplexity, searxng
SEARCH_API=tavily

# Search API Keys
TAVILY_API_KEY=
PERPLEXITY_API_KEY=
SEARXNG_URL=

# Research Settings
MAX_WEB_RESEARCH_LOOPS=3
FETCH_FULL_PAGE=True
USE_TOOL_CALLING=False
STRIP_THINKING_TOKENS=True
